---
title: "Lab 8"
author: "Luis Melo & Akash"
date: "2023-10-27"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

In this lab we prepare to evaluate workforce data. Specifically on individuals who choose to work in the public sector.
We start by loading a couple CSV files that will help identify industry and jobs. 
Then deploy few packages that will help with analytics and statistics

```{r r,echo=FALSE}

load("~/Desktop/ecob2000_Econometrics/Level 3 Lab/acs2021_ny_data.RData")
require(plyr)
require(dplyr)
require(tidyverse)
require(haven)
require(stargazer)

```

To better understand and work with the various codes in the data file we recode as factors with level values

```{r}

levels_n <- read.csv("IND_levels.csv")
names(levels_n) <- c("New_Level","levels_orig")
acs2021$IND <- as.factor(acs2021$IND)
levels_orig <- levels(acs2021$IND) 
levels_new <- join(data.frame(levels_orig),data.frame(levels_n))

acs2021$public_work <- acs2021$IND 
levels_public <- read.csv("publicwork_recode.csv")
names(levels_public) <- c("levels_orig","New_Level")
levels_new_pub <- join(data.frame(levels_orig),data.frame(levels_public))


levels(acs2021$IND) <- levels_new$New_Level
levels(acs2021$public_work) <- levels_new_pub$New_Level

```


Before jumping into our intended goal of modeling we are creating a numeric version for our dependent variable of individuals in the public sector. 

```{r}

acs2021$public_work_num <- as.numeric(acs2021$public_work == "work for public, stable")


table(acs2021$public_work,acs2021$public_work_num)

```

The above table confirms that the variable has been converted to numeric binary values
We define "0" as not working in the public sector, with a result of 83236 individuals
We define "1" as working in the public sector, with a result of 36265 individuals

As we are choosing to model individuals working in the public sector we decide to subset the data to a smaller group.
This group being Women between 25 and 55 in the workforce who have at least a college degree or advanced degree


```{r}

attach(acs2021)
use_varb <- (AGE >= 25) & (AGE <= 55) & (LABFORCE == 2) & (WKSWORK2 > 4) & (UHRSWORK >= 35) & (female == 1) & ((educ_college == 1) | (educ_advdeg == 1))
dat_use <- subset(acs2021,use_varb) # 
detach(acs2021)

```

with this subset we estimate that Hispanic women will have a low probability of working in the public sector despite their level of education

```{r} 

ols_out1 <- lm(public_work_num ~ female + educ_hs + educ_somecoll + educ_college + educ_advdeg + AGE, data = acs2021)
stargazer(ols_out1, type = "text")

```


This model shows that women are less likely to work in the public sector as is despite level of education. However women with advanced degrees are at least twice as likely to work in the public sector over other levels of education


Now we create a new model with the intended purpose of predicting outcomes for our individuals in the public sector who are age 25 to 55 with at least a college degree.

```{r}

pred_vals_ols1 <- predict(ols_out1, dat_use)
pred_model_ols1 <- (pred_vals_ols1 > mean(pred_vals_ols1))

table(pred = pred_model_ols1, true = dat_use$public_work_num)

summary(pred_vals_ols1)

```
*** needs updates
The predicted table shows that there is more of a likelihood for our chosen individual to be in the public sector to not bnased  on the result predicted true and false 2408 > 3811 true and positive 
Given that predicted values chosen are > mean of .4461


Below we will now compare against a logit model with individuals of either sex, an education of at least a high school diploma and any age. 

```{r}

# logit 
model_logit1 <- glm(public_work_num ~ female + educ_hs + educ_somecoll + educ_college + educ_advdeg + AGE, data = acs2021, family = binomial
                    )
summary(model_logit1)
pred_vals_logit1 <- predict(model_logit1, acs2021, type = "response")
pred_model_logit1 <- (pred_vals_logit1 > 0.5)
table(pred = pred_model_logit1, true = acs2021$public_work_num)

```

The above logit model is showing predictors of a bigger variance but same skew of public working individuals women with edeucation 7457 is < 77985 or Men given that the values chosen are > .5

the estimates on this model however show a significant increase in the likelihood of working in the public sector for any female. that is comparing the .136 from our latina with education model to .690 in the all women model

This is a simalr find to levels of education as well. specifically to the advance degree comparison where correlation is almost tripled.
However reviewing highscool and some college would not be good point estimates as our firdt model excluded that level of education. 

---

# Lab 7 Addendum

In the pursuit of furthering our regression modeling comparisons we introduce a new factor as an instrumental variable.
This variable is MET2013, adding location of metropilitan cities of NYS to our comparisons

```{r}

dat_use$MET2013_factor <- as.factor(dat_use$MET2013)

d2_pub_work <- data.frame(model.matrix(~ dat_use$public_work_num)) 


d2_educ_college <- data.frame(model.matrix(~ dat_use$educ_college))
d2_educ_advdeg <- data.frame(model.matrix(~ dat_use$educ_advdeg))
d2_age <- data.frame(model.matrix(~ dat_use$AGE))
d2_MET2013 <- data.frame(model.matrix(~ dat_use$MET2013_factor)) 

```

We then assign all METF2013 variables as factors and create a matrix with our Y and dummy variables. 

We know that some values of 0 can be problematic, so we run the below code to identify that we have no columns with. empty data

```{r}

sum( colSums(d2_MET2013) == 0) # confirmed at 0

```

Once confirmed we create a data table for the new subset with metropiltan area factors.

```{r}

# there are better ways to code this, but choosing my professors!

dat_for_analysis_sub <- data.frame(
  d2_pub_work[,2], # need [] since model.matrix includes intercept term
  
  d2_educ_college[,2],
  d2_educ_advdeg[,2],
  d2_age[,2],
  d2_MET2013[,2:9] ) # this last term is why model.matrix


```

The matrix data table technique was a great choice, not only because it was selected by the professor but also because the data needed was in the second column of the matrix for most variables and spanned from 2nd to 9th in our METfactor variable on our original dat use subset. 


Now being that our professor is also anal retentive, the following code will be removing the repetitive "dat_use" from the column names in our new subset. allowing for easier viewing and recalling in later parts. 
As well as renaming columns 1-12


```{r}

names(dat_for_analysis_sub) <- sub("dat_use.","",names(dat_for_analysis_sub)) # drops each repetition of dat_use

names(dat_for_analysis_sub)[1] <- "pub_work"

names(dat_for_analysis_sub)[2:3] <- c("College","AdvDeg")
names(dat_for_analysis_sub)[4] <- "Age"
names(dat_for_analysis_sub)[5] <- "Albany_NY"
names(dat_for_analysis_sub)[6] <- "Binghamton_NY"
names(dat_for_analysis_sub)[7] <- "Buffalo_NY"
names(dat_for_analysis_sub)[8] <- "GlennFalls_NY"
names(dat_for_analysis_sub)[9] <- "Ithaca_NY"
names(dat_for_analysis_sub)[10] <- "Tristate_NY"
names(dat_for_analysis_sub)[11] <- "Rochester_NY"
names(dat_for_analysis_sub)[12] <- "Syracuse_NY"


# names(dat_for_analysis_sub) # confirming results from above 
#below was a test not to be used
#dat_for_anal_sub2 <- dat_for_analysis_sub[, colSums(dat_for_analysis_sub) != 0]


```

With our new data set complete we will be training an algorithm to assist in our analytics
Starting with setting randomness to the selection of data from public work individuals

```{r}

require("standardize")
set.seed(654321)
NN <- length(dat_for_analysis_sub$pub_work)


```

We then restrict the data selected to a readopnable 30% to train and test the models 

```{r}


restrict_1 <- (runif(NN) < 0.30) # use 10% as training data, ordinarily this would be much bigger but start small
summary(restrict_1)
dat_train <- subset(dat_for_analysis_sub, restrict_1)
dat_test <- subset(dat_for_analysis_sub, !restrict_1)

```

Summary of the 30% selection of 12562 shows 3771 observations will be used for training the algorithm while 8791 is omitted from the data as not meeting the restriction of 30%

Below we confirm the trained data is not inclusive of 0 columns that can skew the data 

```{r}

sum( colSums(dat_train) == 0) # again check this below, should be zero

```

Now we formulate an object that works on regressing the public working individuals and other dummy variables of our subset and proceeds to standardize the data selection from the trained algorithm. 


Sobj prepares the data for modeling by generating a formula, standardizing the data, and finally using the resulting model to make predictions on a separate dataset


```{r}

fmla_sobj <- reformulate( names(dat_for_analysis_sub[2:12]), response = "pub_work")

#remove blanks formula no longer needed as data was changed to work correctly
#fmla_sobj <- update(fmla_sobj, . ~ . - Ithaca_NY)

sobj <- standardize(fmla_sobj, dat_train, family = binomial)

s_dat_test <- predict(sobj, dat_test)

```



Below we will run two models to predict outcomes for the test dataset. 
We will be comparing results from the linear OLS and non linear logit 
Then we produce a summary of the linear regression model to view the coefficients, significance, and goodness-of-fit statistics.  The logistic regression model builds a model as well and utilizes the training data in a similar fashion.  We then produce a summary of the logistic regression model to examining coefficients, significance, and model fit stats.

```{r}

model_lpm1 <- lm(sobj$formula, data = sobj$data)
summary(model_lpm1)
pred_vals_lpm <- predict(model_lpm1, s_dat_test)
pred_model_lpm1 <- (pred_vals_lpm > mean(pred_vals_lpm))
table(pred = pred_model_lpm1, true = dat_test$pub_work)

# logit 
model_logit1 <- glm(sobj$formula, family = binomial, data = sobj$data)
summary(model_logit1)
pred_vals <- predict(model_logit1, s_dat_test, type = "response")
pred_model_logit1 <- (pred_vals > 0.5)
table(pred = pred_model_logit1, true = dat_test$pub_work)


```

it worked!!!!!
fucking finally!!!!


---------------------------

##Lab 8
Start of Lab 8

We will explore comparisons of more models to anylze results from our previous logit and ols models. 
Our aim is that the results from these models should be similar to results from our previous linear and non linear models. 

```{r}

#new addition to include a subset of data inclusive of males for modeling camprisons further down the road.
attach(acs2021)
use_varb2 <- (AGE >= 25) & (AGE <= 55) & (LABFORCE == 2) & (WKSWORK2 > 4) & (UHRSWORK >= 35) & (female == 0) & ((educ_college == 1) | (educ_advdeg == 1))
dat_use2 <- subset(acs2021,use_varb2) # 
use_varb3 <- (AGE >= 25) & (AGE <= 55) & (LABFORCE == 2) & (WKSWORK2 > 4) & (UHRSWORK >= 35) & ((educ_college == 1) | (educ_advdeg == 1))
dat_use3 <- subset(acs2021,use_varb3) # 
detach(acs2021)

# for now, really simplify the education dummy
dat_use$BA_plus <- dat_use$educ_college + dat_use$educ_advdeg
dat_use2$BA_plus <- dat_use2$educ_college + dat_use2$educ_advdeg

dat_use3$BA_plus <- dat_use3$educ_college + dat_use3$educ_advdeg

# whole dataset
model_lpm_v1 <- lm(public_work_num ~ female + BA_plus + AGE + I(female*BA_plus) + I(AGE * female), data = dat_use3)
summary(model_lpm_v1)


dat_use_female <- subset(dat_use,as.logical(dat_use$female))
dat_use_male <- subset(dat_use2,!(dat_use2$female))

# now split into 2 parts
model_lpm_v1f <- lm(public_work_num ~ BA_plus + AGE, data = dat_use_female)
summary(model_lpm_v1f)
model_lpm_v1m <- lm(public_work_num ~ BA_plus + AGE, data = dat_use_male)
summary(model_lpm_v1m)

```

Overall our is to examine the impact of public workers and the dummy variables of age, educcation and interactions between genders. The code allows for separate analysis of the relationship between the dependent variable and the combined education level, age, and gender within the female and male subsets.

The results of the model using the whole dataset of both genders were very similar to the models of any gender alone. Range of min max for both genders were close as well as the estimates. 


Below we start random forest things

```{r}
require('randomForest')
set.seed(54321)
model_randFor <- randomForest(as.factor(pub_work) ~ ., data = sobj$data, importance=TRUE, proximity=TRUE)
print(model_randFor)
round(importance(model_randFor),2)
varImpPlot(model_randFor)
# look at confusion matrix for this too
pred_model1 <- predict(model_randFor,  s_dat_test)
table(pred = pred_model1, true = dat_test$pub_work)

```

Here in comparing both forests we see that location is not as important as education. 


Moving onto support vector machines

```{r}

require(e1071)
# tuned_parameters <- tune.svm(as.factor(pub_work) ~ ., data = sobj$data, gamma = 10^(-3:0), cost = 10^(-2:2)) 
# summary(tuned_parameters)
# figure best parameters and input into next
svm.model <- svm(as.factor(pub_work) ~ ., data = sobj$data, cost = 1, gamma = 0.1)
svm.pred <- predict(svm.model, s_dat_test)
table(pred = svm.pred, true = dat_test$pub_work)

```
these predictor values tell us that based on our sensitivites of outliers to paramters of cost and gamma. the predictor value of 2653 is our predicted true and our predicted false is 2800

thank you goodnight!

